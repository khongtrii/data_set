{"cells":[{"cell_type":"markdown","metadata":{"id":"O88nwPLGp0uK"},"source":["### **FUNCTION SPLIT - DATA PREPROCESSING**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I_NQ2kgui8jL"},"outputs":[],"source":["### Import thư viện\n","from sklearn.preprocessing import StandardScaler\n","from imblearn.over_sampling import RandomOverSampler\n","import numpy as np\n","import pandas as pd\n","import copy\n","\n","### Hàm chia dữ liệu cho train - test - val\n","train, valid, test = np.split(df.sample(frac=1), [int(0.6*len(df)), int(0.8 *len(df))])\n","\n","### Hàm chuẩn hóa dữ liệu - chia dữ liệu\n","### dataframe là (train, test, valid)\n","def getX_y_scaler(dataframe, y_label, x_labels=None, oversample=False):\n","  dataframe = copy.deepcopy(dataframe)\n","  if x_labels is None:\n","    X = dataframe[[c for c in dataframe.columns if c != y_label]].values\n","  else:\n","    if len(x_labels)==1:\n","      X = dataframe[x_labels[0]].values.reshape(-1,1)\n","    else:\n","      X = dataframe[x_labels].values\n","  y = dataframe[y_label].values\n","  scalar = StandardScaler()\n","  X = scalar.fit_transform(X)\n","  if oversample:\n","    ros = RandomOverSampler()\n","    X, y = ros.fit_resample(X, y)\n","\n","  data = np.hstack((X,np.reshape(y, (-1,1))))\n","  return data, X,y"]},{"cell_type":"markdown","metadata":{"id":"FsUPkwqYqMi6"},"source":["###**SOLVE THE MISSING VALUES WITH MEAN**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0OiYDz3tqLr4"},"outputs":[],"source":["### Import thư viện\n","from sklearn.impute import SimpleImputer\n","\n","### Khởi tạo hàm\n","def solve_missing_values(dataframe):\n","  cols = []\n","  for col in dataframe.columns:\n","    missing_data = dataframe[col].isnull().sum()\n","    if missing_data > 0:\n","      cols.append(col)\n","  for i in cols:\n","    imputer = SimpleImputer(strategy='mean')\n","    dataframe[i] = imputer.fit_transform(dataframe[i].values.reshape(-1,1))\n","    dataframe[i] = round(dataframe[i], 3)\n","  data = dataframe\n","  return data"]},{"cell_type":"markdown","metadata":{"id":"2sv4BMshukwp"},"source":["###**SCORE OF MODEL**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"09Oa9JT-wBz7"},"outputs":[],"source":["### Import thư viện tính điểm\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, accuracy_score, f1_score\n","\n","### Khởi tạo hàm\n","def score_model(model, X_score, y_score):\n","  print(model)\n","  print('Score: ', model.score(X_score, y_score))\n","  print(\"MSE: \", mean_squared_error(y_score, model.predict(X_score)))\n","  print(\"MAE: \", mean_absolute_error(y_score, model.predict(X_score)))\n","  print(\"R2: \", r2_score(y_score, model.predict(X_score)))\n","  print(\"Accuracy: \", accuracy_score(y_score, model.predict(X_score)))\n","  print(\"F1: \", f1_score(y_score, model.predict(X_score)))"]},{"cell_type":"markdown","metadata":{"id":"pHAUWSUjulbC"},"source":["###**PLOT PREDICTIONS VALUES, USE WHEN ALL ARE SAME SHAPE**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WjPU8rObxuFs"},"outputs":[],"source":["### Import thư viện\n","import matplotlib.pyplot as plt\n","\n","### Khởi tạo hạm define\n","def plot_predictions(train_data, train_labels, test_data, test_labels, predictions):\n","    plt.figure(figsize=(10,7))\n","    plt.scatter(train_data, train_labels, c=\"b\", label=\"Training data\")\n","    plt.scatter(test_data, test_labels, c=\"g\", label=\"Testing data\")\n","    plt.scatter(test_data, predictions, c=\"r\", label=\"Preditions\")\n","    plt.legend();"]},{"cell_type":"markdown","metadata":{"id":"ZQKp84W8s56Z"},"source":["###**TRAIN _ TEST_ VAL**\n","**MANUAL SPLIT**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6PTWJgJls-S0"},"outputs":[],"source":["### Import thư viện\n","import tensorflow as tf\n","\n","### Chuyển thành tf data\n","tf_data = tf.constant(df)\n","tf_data = tf.cast(tf_data, tf.float32)\n","tf_data = tf.random.shuffle(tf_data)\n","X = tf_data[:, 3:-1]\n","y = tf_data[:,-1]\n","y = tf.expand_dims(y, axis = -1)\n","\n","### Define để chia dữ liệu\n","TRAIN_RATIO = 0.8\n","VAL_RATIO = 0.1\n","TEST_RATIO = 0.1\n","DATASET_SIZE = len(X)\n","\n","X_train = X[:int(DATASET_SIZE*TRAIN_RATIO)]\n","y_train = y[:int(DATASET_SIZE*TRAIN_RATIO)]\n","train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n","train_dataset = train_dataset.shuffle(buffer_size = 8, reshuffle_each_iteration = True).batch(32).prefetch(tf.data.AUTOTUNE)\n","\n","X_val = X[int(DATASET_SIZE*TRAIN_RATIO):int(DATASET_SIZE*(TRAIN_RATIO+VAL_RATIO))]\n","y_val = y[int(DATASET_SIZE*TRAIN_RATIO):int(DATASET_SIZE*(TRAIN_RATIO+VAL_RATIO))]\n","val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n","val_dataset = train_dataset.shuffle(buffer_size = 8, reshuffle_each_iteration = True).batch(32).prefetch(tf.data.AUTOTUNE)\n","\n","X_test = X[int(DATASET_SIZE*(TRAIN_RATIO+VAL_RATIO)):]\n","y_test = y[int(DATASET_SIZE*(TRAIN_RATIO+VAL_RATIO)):]\n","test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n","test_dataset = train_dataset.shuffle(buffer_size = 8, reshuffle_each_iteration = True).batch(32).prefetch(tf.data.AUTOTUNE)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
